{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Loading data and libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-14T18:31:56.039351Z","iopub.status.busy":"2023-11-14T18:31:56.038930Z","iopub.status.idle":"2023-11-14T18:31:57.368883Z","shell.execute_reply":"2023-11-14T18:31:57.367885Z","shell.execute_reply.started":"2023-11-14T18:31:56.039317Z"},"trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np \n","import pandas as pd \n","import os\n","from glob import glob\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","# Number of outputs\n","num_output = 4"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:31:57.371389Z","iopub.status.busy":"2023-11-14T18:31:57.370680Z","iopub.status.idle":"2023-11-14T18:32:18.378164Z","shell.execute_reply":"2023-11-14T18:32:18.376718Z","shell.execute_reply.started":"2023-11-14T18:31:57.371357Z"},"trusted":true},"outputs":[],"source":["#Download dataset\n","\n","!wget -q https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_afccea586afd4ef3bb11fe37dd1ddfbf/Download_KPLabs_Chellenge/train_data.zip\n","!wget -q https://s3.waw2-1.cloudferro.com/swift/v1/AUTH_afccea586afd4ef3bb11fe37dd1ddfbf/Download_KPLabs_Chellenge/test_data.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:32:18.380576Z","iopub.status.busy":"2023-11-14T18:32:18.380043Z","iopub.status.idle":"2023-11-14T18:32:48.024422Z","shell.execute_reply":"2023-11-14T18:32:48.022420Z","shell.execute_reply.started":"2023-11-14T18:32:18.380525Z"},"trusted":true},"outputs":[],"source":["# Extracting dataset\n","\n","!unzip -q train_data.zip\n","!unzip -q test_data.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:32:48.029008Z","iopub.status.busy":"2023-11-14T18:32:48.027932Z","iopub.status.idle":"2023-11-14T18:32:48.043542Z","shell.execute_reply":"2023-11-14T18:32:48.042327Z","shell.execute_reply.started":"2023-11-14T18:32:48.028959Z"},"trusted":true},"outputs":[],"source":["class SpectralCurveFiltering():\n","    \"\"\"\n","    Create a histogram (a spectral curve) of a 3D cube, using the merge_function\n","    to aggregate all pixels within one band. The return array will have\n","    the shape of [CHANNELS_COUNT]\n","    \"\"\"\n","\n","    def __init__(self, merge_function = np.mean):\n","        self.merge_function = merge_function\n","\n","    def __call__(self, sample: np.ndarray):\n","        return self.merge_function(sample, axis=(1, 2))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:32:48.045402Z","iopub.status.busy":"2023-11-14T18:32:48.045021Z","iopub.status.idle":"2023-11-14T18:33:45.317176Z","shell.execute_reply":"2023-11-14T18:33:45.315598Z","shell.execute_reply.started":"2023-11-14T18:32:48.045371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data shape: (1732, 150)\n","Test data shape: (1154, 150)\n"]}],"source":["def load_data(directory: str):\n","    \"\"\"Load each cube, reduce its dimensionality and append to array.\n","\n","    Args:\n","        directory (str): Directory to either train or test set\n","    Returns:\n","        [type]: A list with spectral curve for each sample.\n","    \"\"\"\n","    data = []\n","    filtering = SpectralCurveFiltering(np.sum)\n","    all_files = np.array(\n","        sorted(\n","            glob(os.path.join(directory, \"*.npz\")),\n","            key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n","        )\n","    )\n","    for file_name in all_files:\n","        with np.load(file_name) as npz:\n","            arr = np.ma.MaskedArray(**npz)\n","        arr = filtering(arr)\n","        data.append(arr)\n","    return np.array(data)\n","\n","\n","def load_gt(file_path: str):\n","    \"\"\"Load labels for train set from the ground truth file.\n","    Args:\n","        file_path (str): Path to the ground truth .csv file.\n","    Returns:\n","        [type]: 2D numpy array with soil properties levels\n","    \"\"\"\n","    gt_file = pd.read_csv(file_path)\n","    labels = gt_file[[\"P\", \"K\", \"Mg\", \"pH\"]].values\n","    return labels\n","\n","\n","X_train = load_data(\"/kaggle/working/train_data/train_data\")\n","y_train = load_gt(\"/kaggle/working/train_data/train_gt.csv\")\n","X_test = load_data(\"/kaggle/working/test_data\")\n","\n","print(f\"Train data shape: {X_train.shape}\")\n","print(f\"Test data shape: {X_test.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Scaler"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:45.320033Z","iopub.status.busy":"2023-11-14T18:33:45.319671Z","iopub.status.idle":"2023-11-14T18:33:45.332398Z","shell.execute_reply":"2023-11-14T18:33:45.331488Z","shell.execute_reply.started":"2023-11-14T18:33:45.320002Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:45.334532Z","iopub.status.busy":"2023-11-14T18:33:45.333679Z","iopub.status.idle":"2023-11-14T18:33:45.345661Z","shell.execute_reply":"2023-11-14T18:33:45.344415Z","shell.execute_reply.started":"2023-11-14T18:33:45.334500Z"},"trusted":true},"outputs":[],"source":["#This algorithm follows a pseudo-labeling strategy, where predictions made on the test data by the model are incorporated into the training set \n","#to improve model performance. The process is repeated for each output dimension, \n","#allowing the model to adapt to the specific characteristics of each target variable.\n","def pseudoLabelModels(params):\n","    # List to store predictions for each output dimension\n","    y = []  \n","\n","    for i in range(num_output):\n","        # Set model hyperparameters for the i-th output\n","        model = KNeighborsRegressor(**params[i])\n","        \n","        # Train the model on the i-th output of the training data\n","        model.fit(X_train, y_train[:, i]) \n","        \n","        # Generate pseudo labels for the test data\n","        pseudo_labels = model.predict(X_test)  \n","        \n","        # Combine training and test data along the rows\n","        combined_x = np.vstack((X_train, X_test)) \n","        \n","        # Combine true labels and pseudo labels\n","        combined_y = np.concatenate((y_train[:, i], pseudo_labels)) \n","        \n","        # Re-fit the model using the combined dataset\n","        model.fit(combined_x, combined_y)  \n","        \n","        # Generate final predictions for the test data\n","        y_pred = model.predict(X_test)  \n","        \n","        # Append predictions for the i-th output to the list\n","        y.append(y_pred)  \n","    \n","    # Return the list of predictions for all output dimensions\n","    return y  "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:45.347307Z","iopub.status.busy":"2023-11-14T18:33:45.346976Z","iopub.status.idle":"2023-11-14T18:33:45.362093Z","shell.execute_reply":"2023-11-14T18:33:45.361266Z","shell.execute_reply.started":"2023-11-14T18:33:45.347281Z"},"trusted":true},"outputs":[],"source":["# Defining the parameters for each model\n","\n","params_knn = [{'n_neighbors': 224, 'metric': 'cosine'},\n","              {'n_neighbors': 55, 'metric': 'cosine'},\n","              {'n_neighbors': 49, 'metric': 'cosine'},\n","              {'n_neighbors': 80, 'metric': 'chebyshev'}]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:45.364480Z","iopub.status.busy":"2023-11-14T18:33:45.363437Z","iopub.status.idle":"2023-11-14T18:33:46.667240Z","shell.execute_reply":"2023-11-14T18:33:46.666270Z","shell.execute_reply.started":"2023-11-14T18:33:45.364443Z"},"trusted":true},"outputs":[],"source":["# Execute train and prediction for each model using p\n","\n","y = pseudoLabelModels(params_knn)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:46.672470Z","iopub.status.busy":"2023-11-14T18:33:46.671528Z","iopub.status.idle":"2023-11-14T18:33:46.680441Z","shell.execute_reply":"2023-11-14T18:33:46.679562Z","shell.execute_reply.started":"2023-11-14T18:33:46.672423Z"},"trusted":true},"outputs":[],"source":["# Convert the dataframe into the required format for submission\n","def submission(df, file_name = 'subsmission.csv'):\n","    # Itere sobre as linhas do DataFrame original\n","    data = []\n","    for index, row in df.iterrows():\n","        ID = int(row['ID'])\n","        for col_name in df.columns:\n","            if col_name != 'ID':\n","                col_value = row[col_name]\n","                sample_index = f\"{ID}_{col_name}\"\n","                data.append([sample_index, col_value])\n","    df_result = pd.DataFrame(data, columns=['sample_index', 'Target'])\n","    df_result.to_csv(file_name, index=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:33:46.683487Z","iopub.status.busy":"2023-11-14T18:33:46.682474Z","iopub.status.idle":"2023-11-14T18:33:46.835030Z","shell.execute_reply":"2023-11-14T18:33:46.833712Z","shell.execute_reply.started":"2023-11-14T18:33:46.683429Z"},"trusted":true},"outputs":[],"source":["# Generate submission file\n","df_knn = pd.DataFrame(data = (np.array([y[0], y[1], y[2], y[3]]).T)/[70.3026558891455,227.9885103926097,159.28123556581986,6.782719399538106], columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n","df_knn['ID'] = range(0, len(df_knn))\n","df_knn = df_knn[['ID', 'P', 'K', 'Mg', 'pH']]\n","submission(df_knn, \"final_submission.csv\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30579,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
